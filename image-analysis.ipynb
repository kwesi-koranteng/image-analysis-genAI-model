{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f31af685-7c85-4d76-84cb-59b0f9be39b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Whispers of wind on wildflower hues.\n",
      "- Rugged pack rests in sunshine's embrace.\n",
      "- Grass-scented earth cradles journey's hold.\n",
      "- Cool aqua quenches; blue carries onward.\n",
      "- Maps unfold; mountains sing freedom.\n",
      "- Tough fibers meet tender alpine blooms.\n",
      "- Whispers of rock: ancient strength unveiled.\n",
      "- Sky's echo in water’s gleaming sheen.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import base64\n",
    "\n",
    "def generate():\n",
    "  client = genai.Client(\n",
    "      vertexai=True,\n",
    "      project=\"qwiklabs-gcp-00-94a456e9fb5f\",\n",
    "      location=\"us-central1\",\n",
    "  )\n",
    "\n",
    "  msg1_image1 = types.Part.from_uri(\n",
    "      file_uri=\"gs://qwiklabs-gcp-00-94a456e9fb5f-labconfig-bucket/cymbal-product-image.png\",\n",
    "      mime_type=\"image/png\",\n",
    "  )\n",
    "  msg1_text1 = types.Part.from_text(text=\"\"\"You are analyzing a Cymbal Direct outdoor product image.\n",
    "\n",
    "Produce:\n",
    "1) 5 short descriptive lines (≤ 15 words each) that highlight visible materials, colors, and intended use.\n",
    "2) 5 catchy ad phrases (≤ 10 words each) suitable for social ads.\n",
    "3) 1 poetic, nature-focused paragraph (2–3 sentences) evoking mood, place, and movement.\n",
    "\n",
    "Rules:\n",
    "- Do not invent features not visible in the image.\n",
    "- Avoid brand comparisons or guarantees.\n",
    "- Use approachable, sensory language.\n",
    "\n",
    "Output format:\n",
    "- Short Descriptions: (one per line)\n",
    "- Catchy Phrases: (one per line)\n",
    "- Poetic Description:\"\"\")\n",
    "  msg2_text1 = types.Part.from_text(text=\"\"\"Okay, I'm ready. Here's the analysis of the image:\n",
    "\n",
    "- Short Descriptions:\n",
    "  - Blue backpack rests near a wildflower-lined mountain path.\n",
    "  - A hydration bottle is visible in the backpack's side pocket.\n",
    "  - Hiking map lies open on the grassy slope.\n",
    "  - The scene showcases vibrant greens and natural textures.\n",
    "  - Perfect gear for outdoor hiking and exploration.\n",
    "\n",
    "- Catchy Phrases:\n",
    "  - Explore the wild. Pack your dreams.\n",
    "  - Adventure awaits! Get ready to roam.\n",
    "  - Nature's beauty, ready to embrace.\n",
    "  - Your journey starts here. Hike on!\n",
    "  - Gear up. Get out. Discover more.\n",
    "\n",
    "- Poetic Description:\n",
    "  The sun-dappled path winds through emerald slopes, dotted with a tapestry of wildflowers. A sturdy blue backpack rests, a silent invitation to wander deeper into the heart of the mountains.\"\"\")\n",
    "  msg3_image1 = types.Part.from_uri(\n",
    "      file_uri=\"gs://qwiklabs-gcp-00-94a456e9fb5f-labconfig-bucket/cymbal-product-image.png\",\n",
    "      mime_type=\"image/png\",\n",
    "  )\n",
    "  msg3_text1 = types.Part.from_text(text=\"\"\"In under 10 words each, generate 8 startlingly creative, sensory descriptions\n",
    "of this product’s look, materials, and outdoor mood. Avoid brand names.\n",
    "Return one description per line.\"\"\")\n",
    "\n",
    "  model = \"gemini-2.0-flash-001\"\n",
    "  contents = [\n",
    "    types.Content(\n",
    "      role=\"user\",\n",
    "      parts=[\n",
    "        msg1_image1,\n",
    "        msg1_text1\n",
    "      ]\n",
    "    ),\n",
    "    types.Content(\n",
    "      role=\"model\",\n",
    "      parts=[\n",
    "        msg2_text1\n",
    "      ]\n",
    "    ),\n",
    "    types.Content(\n",
    "      role=\"user\",\n",
    "      parts=[\n",
    "        msg3_image1,\n",
    "        msg3_text1\n",
    "      ]\n",
    "    ),\n",
    "  ]\n",
    "\n",
    "  generate_content_config = types.GenerateContentConfig(\n",
    "    temperature=1.3,      # higher = more creative\n",
    "    top_p=0.95,\n",
    "    max_output_tokens=128, # short is fine since outputs are short\n",
    "    safety_settings = [types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "      threshold=\"OFF\"\n",
    "    )],\n",
    "  )\n",
    "\n",
    "  for chunk in client.models.generate_content_stream(\n",
    "    model = model,\n",
    "    contents = contents,\n",
    "    config = generate_content_config,\n",
    "    ):\n",
    "    print(chunk.text, end=\"\")\n",
    "\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864a662-599c-4e4f-ac89-92a871add07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
